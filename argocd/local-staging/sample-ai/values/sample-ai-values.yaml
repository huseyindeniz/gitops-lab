inference-api:
  env:
    FLASK_ENV: "staging"
    COMMAND: "app"
    PORT: 80
    RUN_ON_GPU: "0"
    ALLOWED_EXTENSIONS: "png,jpg,jpeg"
    MODELS_FOLDER: "/app/data/models"
    UPLOAD_FOLDER: "/app/data/uploads"
    OUTPUT_FOLDER: "/app/data/outputs"

  progressDeadlineSeconds: 1800

  replicaCount: 1

  image:
    repository: harbor.staging.local:30443/library/sample-ai-inference-api-staging
    pullPolicy: IfNotPresent
    tag: "20251201205024"
    # from ghcr
    # repository: ghcr.io/huseyindeniz/sample-ai-inference-api-staging # image size is 14.8GB, compresses size: 8.76GB
    # pullPolicy: IfNotPresent
    # tag: "20250316135546"
  registryAuth:
    - username: Admin
    - password: Harbor12345 # this is local gitops lab, will be replaced as secret later

  nameOverride: "sample-ai-inference-api"
  fullnameOverride: "sample-ai-inference-api-staging"

  podAnnotations: {}
  podLabels: {}

  resources:
    requests:
      cpu: "500m"
      memory: "2Gi"
    limits:
      cpu: "2"
      memory: "4Gi"
      nvidia.com/gpu: "1"

  service:
    type: ClusterIP
    port: 80
    targetPort: 80

  ingress:
    enabled: false

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 80

  volumeMounts:
    - name: sample-ai-backend-volume
      mountPath: /app/data

  volumes:
    - name: sample-ai-backend-volume
      persistentVolumeClaim:
        claimName: sample-ai-backend-volume-pvc

frontend:
  replicaCount: 1

  image:
    repository: huseyindeniz/sample-ai-frontend-staging
    pullPolicy: IfNotPresent
    tag: "20250226214657"
    # from harbor
    # repository: 10.111.194.0:30080/library/sample-ai-frontend-staging
    # tag: "20250413070918"

  nameOverride: "sample-ai-frontend"
  fullnameOverride: "sample-ai-frontend-staging"

  podAnnotations: {}
  podLabels: {}

  service:
    type: ClusterIP
    port: 80
    targetPort: 80

  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: sample-ai-frontend-staging.local
        paths:
          - path: /
            pathType: Prefix

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80
