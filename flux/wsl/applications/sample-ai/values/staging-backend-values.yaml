env:
  FLASK_ENV: "staging"
  PORT: 8000

progressDeadlineSeconds: 1800

replicaCount: 0

image:
  repository: ghcr.io/huseyindeniz/sample-ai-backend-staging # image size is 14.8GB, compresses size: 8.76GB
  pullPolicy: IfNotPresent
  tag: "20250124165727"

nameOverride: "sample-ai-backend"
fullnameOverride: "sample-ai-backend-staging"

podAnnotations: {}
podLabels: {}

resources:
  requests:
    cpu: "250m"
    memory: "1Gi"
  limits:
    cpu: "500m"
    memory: "2Gi"
    nvidia.com/gpu: "1"

service:
  type: LoadBalancer
  port: 8000
  targetPort: 8000

ingress:
  enabled: true
  className: ""
  annotations: {}
  hosts:
    - host: sample-ai-backend-staging.local
      paths:
        - path: /
          pathType: Prefix

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 60
  targetMemoryUtilizationPercentage: 80

volumeMounts:
  - name: sample-ai-backend-volume
    mountPath: /app/data

volumes:
  - name: sample-ai-backend-volume
    persistentVolumeClaim:
      claimName: sample-ai-backend-volume-pvc
